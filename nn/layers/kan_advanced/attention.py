# """
# @author   Maksim Penkin
# """

import torch.nn as nn


class AttentionKANLinear(nn.Module):
    def __init__(self, input_dim, output_dim, degree):
        super(AttentionKANLinear, self).__init__()

    def forward(self, x):
        return
