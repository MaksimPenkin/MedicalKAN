module: torch.optim
class_name: AdamW
config:
  lr: 0.0001
  weight_decay: 0.01