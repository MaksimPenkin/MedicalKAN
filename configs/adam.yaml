module: torch.optim
class_name: Adam
config:
  lr: 0.001
